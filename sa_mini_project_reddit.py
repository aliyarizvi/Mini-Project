# -*- coding: utf-8 -*-
"""SA_Mini_Project_Reddit

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aw1JruxujL6MSlxSH29arzA7U47TXKCI
"""

import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

path = "https://raw.githubusercontent.com/devvratmiglani/SA_Mini_Project_5th_SEM/main/mental_health.csv"
df = pd.read_csv(path)

"""## **Data Preprocessing**"""

df.head()

df.info()

# checking missing values
df.isnull().sum()

# checking for duplicate values
df[df.duplicated()]

#dropping duplicate values
df = df.drop_duplicates()

df[df.duplicated()]

import matplotlib.pyplot as plt

category_counts = df['label'].value_counts()

# Bar chart
plt.figure(figsize=(6, 4))
category_counts.plot(kind='bar')
plt.xlabel('Label')
plt.ylabel('Counts')
plt.show()
print()

plt.show()

# Word Cloud

stress_data = df[df['label'] == 1]['text']
nonstress_data = df[df['label'] == 0]['text']

from wordcloud import WordCloud

# Function to generate word cloud for a given text data
def generate_wordcloud(data, title):
    wordcloud = WordCloud(width = 800, height = 800,
                          background_color ='black',
                          min_font_size = 10).generate(' '.join(data))

    plt.figure(figsize = (8, 8), facecolor = None)
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.tight_layout(pad = 0)

    plt.title(title)
    plt.show()

# Generate word cloud for mental class
generate_wordcloud(stress_data, 'Stress Class Word Cloud')

generate_wordcloud(nonstress_data, 'Non-Stress Class Word Cloud')

"""# **Lemmatization**

"""

# it is a method by which we can turn the words into their base form ie simpler form which eventually helps us to perform and train our model well

import nltk
nltk.download('wordnet')
nltk.download('punkt')

from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

lemmatizer = WordNetLemmatizer()

def text_lemmatize(text):
    word_list = nltk.word_tokenize(text) # tokenize the sentence

    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])  # Lemmatize list of words and join

    return lemmatized_output

df['text'] = df['text'].apply(text_lemmatize)

df.head(5)

# removal of stop words

def remove_stopwords(sentence):
    stopwords = ["a", "about", "above", "after", "again", "against", "all", "am", "an", "and", "any", "are", "as", "at", "be", "because", "been", "before", "being", "below", "between", "both", "but", "by", "could", "did", "do", "does", "doing", "down", "during", "each", "few", "for", "from", "further", "had", "has", "have", "having",
                 "he", "he'd", "he'll", "he's", "her", "here", "here's", "hers", "herself", "him", "himself", "his", "how", "how's", "i", "i'd", "i'll", "i'm", "i've", "if", "in", "into", "is", "it", "it's", "its", "itself", "let's", "me", "more", "most", "my", "myself", "nor", "of", "on", "once", "only", "or", "other", "ought", "our", "ours", "ourselves", "out",
                 "over", "own", "same", "she", "she'd", "she'll", "she's", "should", "so", "some", "such", "than", "that", "that's", "the", "their", "theirs", "them", "themselves", "then", "there", "there's", "these", "they", "they'd", "they'll", "they're", "they've", "this", "those", "through", "to", "too", "under", "until", "up", "very", "was",
                 "we", "we'd", "we'll", "we're", "we've", "were", "what", "what's", "when", "when's", "where", "where's", "which", "while", "who", "who's", "whom", "why", "why's", "with", "would", "you", "you'd", "you'll", "you're", "you've", "your", "yours", "yourself", "yourselves" ]

    sentence = sentence.lower()

    words = sentence.split()
    no_words = [w for w in words if w not in stopwords]
    sentence = " ".join(no_words)

    return sentence

df['text'] = df['text'].apply(remove_stopwords)

df['label_name'] = df.label.map({
    0: 'No stress',
    1: 'Stress'
})

df.head(5)

# splitting the data into train and test set

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    df.text,
    df.label,
    test_size=0.3, # 30% samples will go to test dataset ie 70-30
    random_state=42,
    stratify=df.label
)

print("Shape of X_train: ", X_train.shape)
print("Shape of X_test: ", X_test.shape)

X_train.head()

# we will be using tf-idf for text vectorization which is simply converting the text into mumeric vectors

#1. Multinomial Naive Bayes Classifier

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_recall_curve, auc, accuracy_score
from sklearn.ensemble import StackingClassifier
from sklearn.ensemble import GradientBoostingClassifier

classification_reports = {}

mnb_model = Pipeline([
     ('vectorizer_tfidf',TfidfVectorizer()),
     ('MultinomialNB', MultinomialNB(alpha=1.0))
])

mnb_model.fit(X_train, y_train)

y_pred = mnb_model.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Multinomial Naive Bayes Classifier'] = CR
print(CR)

# Multinomial Naive Bayes has the accuracy of 85%

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve
y_probs = mnb_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

X_test[:5]

y_test[:5]

y_pred[:5]

#2. Random Forest Classifier

from sklearn.ensemble import RandomForestClassifier

rf_model = Pipeline([
     ('vectorizer_tfidf',TfidfVectorizer()),
     ('Random Forest', RandomForestClassifier())
])

rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Random Forest Classifier'] = CR
print(CR)

# Random Forest Classifier has the accuracy of 90%

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve
y_probs = rf_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

#3. Support Vector Machine

from sklearn.svm import SVC

svm_model = Pipeline([
     ('vectorizer_tfidf',TfidfVectorizer()),
     ('SVC', SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42))
])

svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Support Vector Machine'] = CR
print(CR)

# Support Vector Machine has the accuracy of 92%

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve
y_probs = svm_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# 4. Decision Tree Classifier

from sklearn.tree import DecisionTreeClassifier

dt_model = Pipeline([
     ('vectorizer_tfidf',TfidfVectorizer()),
     ('Decision Tree', DecisionTreeClassifier())
])

dt_model.fit(X_train, y_train)

y_pred = dt_model.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Decision Tree Classifier'] = CR
print(CR)

# Decision Tree has the accuracy of 84%

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve
y_probs = dt_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Final Ensemble Classifier
# We'll be using the ensemble voting classifier and the soft voting method. As the accuracy of Random Forest classifier and SVM
# is seen to be better than Decision Tree and Multinomial Naive Bayes, we'll be using them as the base classifiers in the ensemble classifier

from sklearn.ensemble import VotingClassifier

voting_classifier = VotingClassifier(
    estimators=[
        ('Random Forest', rf_model),
        ('SVM', svm_model)
    ],
    voting='soft'
)

voting_classifier.fit(X_train, y_train)
y_pred = voting_classifier.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Final Ensemble Classifier'] = CR
print(CR)

#Final Ensemble accuracy is 92% (when only models with best accuracy were selected)
#if we remove our best classifier that is svm, the accuracy falls down to 88%

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# ROC Curve
y_probs = voting_classifier.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Saving the final voting classifier

import joblib

voting_classifier.fit(X_train, y_train)

joblib.dump(voting_classifier, 'voting_classifier_model.pkl')

# # Later, when you want to use the model for prediction
# loaded_voting_classifier = joblib.load('voting_classifier_model.pkl')

# Assuming 'new_data' is the new data you want to predict on
# predictions = loaded_voting_classifier.predict(new_data)

# #Hard voting trial

# from sklearn.ensemble import VotingClassifier

# voting_classifier = VotingClassifier(
#     estimators=[
#         ('Random Forest', rf_model),
#         ('SVM', svm_model)
#     ],
#     voting='hard'
# )

# voting_classifier.fit(X_train, y_train)
# y_pred = voting_classifier.predict(X_test)

# CR = classification_report(y_test, y_pred)
# classification_reports['Final Ensemble Classifier'] = CR
# print(CR)

# # Stacking

# base_models = [
#     ('SVM', SVC(probability=True)),
#     ('DecisionTree', DecisionTreeClassifier()),
#     ('RandomForest', RandomForestClassifier()),
#     ('MultinomialNB', MultinomialNB())
# ]

# # Define meta-model
# meta_model = StackingClassifier(estimators=base_models)

# # Create a pipeline with TF-IDF vectorizer and StackingClassifier
# pipeline = Pipeline([
#     ('vectorizer_tfidf', TfidfVectorizer()),
#     ('stacking_classifier', meta_model)
# ])

# # Fit the pipeline
# pipeline.fit(X_train, y_train)

# # Make predictions
# y_pred_stacking = pipeline.predict(X_test)

# # Evaluate the stacking classifier
# stacking_accuracy = accuracy_score(y_test, y_pred_stacking)
# print("Stacking Classifier Accuracy:", stacking_accuracy)

# bar graphs

models = ['MNB', 'Random Forest', 'SVM', 'Decision Tree', 'Voting Classifier']
accuracy_values = [85, 90, 92, 84, 92]
colors = ['blue', 'green', 'orange', 'red', 'purple']

bars = plt.bar(models, accuracy_values, color=colors)

plt.ylabel('Accuracy')
plt.xlabel('Models')
plt.title('Accuracy of trained Models')
plt.xticks(rotation=20)

for bar, value in zip(bars, accuracy_values):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2f}',
             ha='center', va='bottom')

plt.show()

"""## **BAG OF WORDS**"""

# Results with Bag of Words vectorization Technique

# 1. Multinomial Naive Bayes Classifier

from sklearn.feature_extraction.text import CountVectorizer

mnb_bow_model = Pipeline([
     ('vectorizer_bow',CountVectorizer()),
     ('MultinomialNB', MultinomialNB())
])

mnb_bow_model.fit(X_train, y_train)

y_pred = mnb_bow_model.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Multinomial Naive Bayes Classifier (BOW)'] = CR
print(CR)

# Accuracy is 84%

#2. Random Forest Classifier

from sklearn.ensemble import RandomForestClassifier

rf_bow_model = Pipeline([
     ('vectorizer_bow',CountVectorizer()),
     ('Random Forest', RandomForestClassifier())
])

rf_bow_model.fit(X_train, y_train)

y_pred = rf_bow_model.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Random Forest Classifier'] = CR
print(CR)

# Accuracy is 90%

# 3. Support Vector Machine

from sklearn.svm import SVC

svm_bow_model = Pipeline([
     ('vectorizer_bow',CountVectorizer()),
     ('SVC', SVC(probability=True))
])

svm_bow_model.fit(X_train, y_train)

y_pred = svm_bow_model.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Support Vector Machine'] = CR
print(CR)

#

# 4. Decision Tree Classifier

from sklearn.tree import DecisionTreeClassifier

dt_bow_model = Pipeline([
     ('vectorizer_bow',CountVectorizer()),
     ('Decision Tree', DecisionTreeClassifier())
])

dt_bow_model.fit(X_train, y_train)

y_pred = dt_bow_model.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Decision Tree Classifier'] = CR
print(CR)

# Final Ensemble Classifier
# We'll be using the ensemble voting classifier and the soft voting method. As the accuracy of Random Forest classifier, SVM, Gradient Bossting & Multinomial Naive Bayes
# is seen to be better than Decision Tree, we'll be using them as the base classifiers in the ensemble classifiers

from sklearn.ensemble import VotingClassifier

voting_classifier_bow = VotingClassifier(
    estimators=[
        ('SVM', svm_bow_model),
        ('Random Forest', rf_bow_model),
    ],
    voting='soft'  # Soft voting for probability-based weighting
)

voting_classifier_bow.fit(X_train, y_train)
y_pred = voting_classifier_bow.predict(X_test)

CR = classification_report(y_test, y_pred)
classification_reports['Final Ensemble Classifier'] = CR
print(CR)